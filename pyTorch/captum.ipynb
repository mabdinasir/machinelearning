{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Captum (“comprehension” in Latin) is an open source, extensible library for model interpretability built on PyTorch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Captum provides state-of-the-art algorithms, including Integrated Gradients, to provide researchers and developers with an easy way to understand which features are contributing to a model’s output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Attribution: seeks to explain a particular output in terms of features of the input that generated it. Explaining whether a movie review was positive or negative in terms of certain words in the review is an example of feature attribution.\n",
    "\n",
    "### Layer Attribution: examines the activity of a model’s hidden layer subsequent to a particular input. Examining the spatially-mapped output of a convolutional layer is response to an input image in an example of layer attribution.\n",
    "\n",
    "### Neuron Attribution: is analagous to layer attribution, but focuses on the activity of a single neuron.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many attribution algorithms fall into two broad categories:\n",
    "\n",
    "#### Gradient-based algorithms calculate the backward gradients of a model output, layer output, or neuron activation with respect to the input. Integrated Gradients (for features), Layer Gradient \\* Activation, and Neuron Conductance are all gradient-based algorithms.\n",
    "\n",
    "#### Perturbation-based algorithms examine the changes in the output of a model, layer, or neuron in response to changes in the input. The input perturbations may be directed or random. Occlusion, Feature Ablation, and Feature\n",
    "\n",
    "#### Permutation are all perturbation-based algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import captum\n",
    "from captum.attr import IntegratedGradients, Occlusion, LayerGradCam, LayerAttribution\n",
    "from captum.attr import visualization as viz\n",
    "\n",
    "import os, sys\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = Image.open('../data/img/cat.jpg')\n",
    "test_img_data = np.asarray(test_img)\n",
    "plt.imshow(test_img_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model expects 224x224 3-color image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# standard ImageNet normalization\n",
    "transform_normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "\n",
    "transformed_img = transform(test_img)\n",
    "input_img = transform_normalize(transformed_img)\n",
    "input_img = input_img.unsqueeze(0) # the model requires a dummy batch dimension\n",
    "\n",
    "labels_path = '../data/img/imagenet_class_index.json'\n",
    "with open(labels_path) as json_data:\n",
    "    idx_to_labels = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_img) # forward pass\n",
    "output = F.softmax(output, dim=1) # softmax to get probabilities\n",
    "prediction_score, pred_label_idx = torch.topk(output, 1)\n",
    "pred_label_idx.squeeze_()\n",
    "predicted_label = idx_to_labels[str(pred_label_idx.item())][1]\n",
    "print('Predicted:', predicted_label, '(', prediction_score.squeeze().item(), ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the attribution algorithm with the model\n",
    "integrated_gradients = IntegratedGradients(model)\n",
    "\n",
    "# Ask the algorithm to attribute our output target to\n",
    "attributions_ig = integrated_gradients.attribute(input_img, target=pred_label_idx, n_steps=200)\n",
    "\n",
    "# Show the original image for comparison\n",
    "# _ = viz.visualize_image_attr(None, np.transpose(transformed_img.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "#                       method=\"original_image\", title=\"Original Image\")\n",
    "\n",
    "default_cmap = LinearSegmentedColormap.from_list('custom blue',\n",
    "                                                [(0, '#ffffff'),\n",
    "                                                (0.25, '#0000ff'),\n",
    "                                                (1, '#0000ff')], N=256)\n",
    "\n",
    "_ = viz.visualize_image_attr(np.transpose(attributions_ig.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                            np.transpose(transformed_img.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                            method='heat_map',\n",
    "                            cmap=default_cmap,\n",
    "                            show_colorbar=True,\n",
    "                            sign='positive',\n",
    "                            title='Integrated Gradients')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
