{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example illustrates all of what you need to know to get started with the new torchvision.transforms.v2 API. Weâ€™ll cover simple tasks like image classification, and more advanced ones like object detection / segmentation.\n",
    "\n",
    "First, a bit of setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.io import read_image\n",
    "from helpers import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# If you're trying to run that on collab, you can download the assets and the\n",
    "# helpers from https://github.com/pytorch/vision/tree/main/gallery/\n",
    "img = read_image(str(Path('../assets') / 'astronaut.jpg'))\n",
    "print(f\"{type(img) = }, {img.dtype = }, {img.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If you just care about image classification, things are very simple. A basic classification pipeline may look like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.RandomCrop(size=(224, 224))\n",
    "out = transform(img)\n",
    "\n",
    "plot([img, out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = v2.Compose([\n",
    "    v2.RandomResizedCrop(size=(224, 224), antialias=True),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "out = transforms(img)\n",
    "\n",
    "plot([img, out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection, Segmentation, Videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import tv_tensors\n",
    "\n",
    "boxes = tv_tensors.BoundingBoxes(\n",
    "    [\n",
    "        [15, 10, 370, 510],\n",
    "        [275, 340, 510, 510],\n",
    "        [130, 345, 210, 425]\n",
    "    ],\n",
    "    format=\"XYXY\", canvas_size=img.shape[-2:])\n",
    "\n",
    "transforms = v2.Compose([\n",
    "    v2.RandomResizedCrop(size=(224, 224), antialias=True),\n",
    "    v2.RandomPhotometricDistort(p=1),\n",
    "    v2.RandomHorizontalFlip(p=1),\n",
    "])\n",
    "out_img, out_boxes = transforms(img, boxes)\n",
    "print(type(boxes), type(out_boxes))\n",
    "\n",
    "plot([(img, boxes), (out_img, out_boxes)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "` TVTensors are torch.Tensor subclasses. The available TVTensors are Image, BoundingBoxes, Mask, and Video.`\n",
    "\n",
    "`TVTensors look and feel just like regular tensors - they are tensors. Everything that is supported on a plain torch.Tensor like .sum() or any torch.\\* operator will also work on a TVTensor:`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isinstance(img_dp, torch.Tensor) = True\n",
      "img_dp.dtype = torch.uint8, img_dp.shape = torch.Size([3, 256, 256]), img_dp.sum() = tensor(25151131)\n"
     ]
    }
   ],
   "source": [
    "img_dp = tv_tensors.Image(torch.randint(0, 256, (3, 256, 256), dtype=torch.uint8))\n",
    "\n",
    "print(f\"{isinstance(img_dp, torch.Tensor) = }\")\n",
    "print(f\"{img_dp.dtype = }, {img_dp.shape = }, {img_dp.sum() = }\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
