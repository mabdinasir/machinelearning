{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch                     # for all things PyTorch\n",
    "import torch.nn as nn            # for torch.nn.Module, the parent object for PyTorch models\n",
    "import torch.nn.functional as F  # for the activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn.Module\n",
    "\n",
    "### PyTorch base class meant to encapsulate behaviors specific to PyTorch Models and their components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model:\n",
      "TinyModel(\n",
      "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "\n",
      "\n",
      "Just one layer:\n",
      "Linear(in_features=200, out_features=10, bias=True)\n",
      "\n",
      "\n",
      "Model params:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0636, -0.0642,  0.0836,  ...,  0.0769,  0.0700, -0.0863],\n",
      "        [-0.0265,  0.0723, -0.0642,  ..., -0.0276, -0.0171, -0.0007],\n",
      "        [-0.0558, -0.0938,  0.0804,  ..., -0.0170, -0.0043,  0.0638],\n",
      "        ...,\n",
      "        [ 0.0080,  0.0462,  0.0293,  ...,  0.0191,  0.0253, -0.0472],\n",
      "        [ 0.0822,  0.0016, -0.0180,  ...,  0.0374,  0.0943,  0.0608],\n",
      "        [-0.0666,  0.0545,  0.0786,  ...,  0.0687,  0.0679, -0.0440]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0062,  0.0739, -0.0933,  0.0564,  0.0409,  0.0467,  0.0459, -0.0539,\n",
      "        -0.0150,  0.0497, -0.0374,  0.0742,  0.0079, -0.0923, -0.0961, -0.0704,\n",
      "         0.0828, -0.0573,  0.0010, -0.0679, -0.0187,  0.0677,  0.0537, -0.0118,\n",
      "         0.0608, -0.0487,  0.0522, -0.0881,  0.0449,  0.0272,  0.0989, -0.0242,\n",
      "        -0.0399,  0.0736,  0.0705,  0.0736,  0.0642, -0.0918, -0.0459, -0.0877,\n",
      "         0.0352, -0.0500, -0.0765, -0.0745,  0.0671,  0.0213, -0.0950,  0.0673,\n",
      "        -0.0498,  0.0120, -0.0448, -0.0192,  0.0847, -0.0576, -0.0127, -0.0516,\n",
      "         0.0196, -0.0583,  0.0625,  0.0951,  0.0419, -0.0069,  0.0831,  0.0196,\n",
      "         0.0941, -0.0595,  0.0737,  0.0014, -0.0702, -0.0628,  0.0780,  0.0569,\n",
      "        -0.0347, -0.0671,  0.0682, -0.0653, -0.0571,  0.0320, -0.0701, -0.0708,\n",
      "         0.0090,  0.0761, -0.0137,  0.0751,  0.0105,  0.0344, -0.0041, -0.0396,\n",
      "        -0.0912, -0.0860,  0.0916,  0.0154,  0.0552,  0.0662, -0.0773,  0.0192,\n",
      "         0.0484,  0.0438, -0.0358,  0.0084,  0.0284, -0.0335, -0.0554, -0.0949,\n",
      "        -0.0753, -0.0257, -0.0239, -0.0280,  0.0485, -0.0939,  0.0789, -0.0243,\n",
      "         0.0197, -0.0016,  0.0914, -0.0531, -0.0728, -0.0735, -0.0723,  0.0895,\n",
      "        -0.0147, -0.0602, -0.0488,  0.0197, -0.0319, -0.0224,  0.0718, -0.0293,\n",
      "        -0.0695,  0.0909, -0.1000,  0.0680, -0.0889,  0.0178, -0.0160, -0.0016,\n",
      "        -0.0693,  0.0088,  0.0963, -0.0667,  0.0356, -0.0422, -0.0049,  0.0769,\n",
      "         0.0309,  0.0387, -0.0420,  0.0073,  0.0276, -0.0579,  0.0247,  0.0845,\n",
      "         0.0033, -0.0818, -0.0484, -0.0074,  0.0160, -0.0537, -0.0221, -0.0045,\n",
      "        -0.0087,  0.0237,  0.0686, -0.0063, -0.0304,  0.0525,  0.0597, -0.0128,\n",
      "         0.0839, -0.0493, -0.0564, -0.0424,  0.0761, -0.0448,  0.0832, -0.0901,\n",
      "        -0.0328, -0.0573, -0.0127, -0.0258,  0.0649,  0.0577,  0.0517,  0.0578,\n",
      "        -0.0526,  0.0833, -0.0390, -0.0314,  0.0622, -0.0483, -0.0738,  0.0331,\n",
      "         0.0194, -0.0779, -0.0041,  0.0684,  0.0799,  0.0583,  0.0892,  0.0339],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0118, -0.0580, -0.0690,  ...,  0.0083,  0.0340,  0.0593],\n",
      "        [-0.0478, -0.0176,  0.0184,  ...,  0.0561,  0.0203, -0.0583],\n",
      "        [ 0.0224,  0.0016, -0.0150,  ...,  0.0362, -0.0427,  0.0604],\n",
      "        ...,\n",
      "        [-0.0295, -0.0084,  0.0185,  ..., -0.0700, -0.0468,  0.0208],\n",
      "        [-0.0079,  0.0185, -0.0470,  ..., -0.0697,  0.0339, -0.0297],\n",
      "        [ 0.0666, -0.0436,  0.0681,  ..., -0.0226,  0.0237, -0.0066]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0448, -0.0620,  0.0398,  0.0469,  0.0268,  0.0528,  0.0512,  0.0334,\n",
      "        -0.0482,  0.0274], requires_grad=True)\n",
      "\n",
      "\n",
      "Layer params:\n",
      "Parameter containing:\n",
      "tensor([[-0.0118, -0.0580, -0.0690,  ...,  0.0083,  0.0340,  0.0593],\n",
      "        [-0.0478, -0.0176,  0.0184,  ...,  0.0561,  0.0203, -0.0583],\n",
      "        [ 0.0224,  0.0016, -0.0150,  ...,  0.0362, -0.0427,  0.0604],\n",
      "        ...,\n",
      "        [-0.0295, -0.0084,  0.0185,  ..., -0.0700, -0.0468,  0.0208],\n",
      "        [-0.0079,  0.0185, -0.0470,  ..., -0.0697,  0.0339, -0.0297],\n",
      "        [ 0.0666, -0.0436,  0.0681,  ..., -0.0226,  0.0237, -0.0066]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0448, -0.0620,  0.0398,  0.0469,  0.0268,  0.0528,  0.0512,  0.0334,\n",
      "        -0.0482,  0.0274], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(100, 200) # 100 input features, 200 output features\n",
    "        self.activation = torch.nn.ReLU()        # activation function\n",
    "        self.linear2 = torch.nn.Linear(200, 10)  # 200 input features, 10 output features\n",
    "        self.softmax = torch.nn.Softmax()       # softmax function for the output layer\n",
    "\n",
    "    # Forward pass is where the computation happens\n",
    "    # we first pass the input through the first linear layer, then apply the activation function\n",
    "    # then pass it through the second linear layer and apply the softmax function\n",
    "    # the output is the prediction\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "tinymodel = TinyModel()\n",
    "\n",
    "print('The model:')\n",
    "print(tinymodel)\n",
    "\n",
    "print('\\n\\nJust one layer:')\n",
    "print(tinymodel.linear2)\n",
    "\n",
    "print('\\n\\nModel params:')\n",
    "for param in tinymodel.parameters():\n",
    "    print(param)\n",
    "\n",
    "# The parameters are the weights and biases of the linear layers, which are initialized randomly\n",
    "# The weights and biases of the linear layers are learned during training\n",
    "print('\\n\\nLayer params:')\n",
    "for param in tinymodel.linear2.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Layer Types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Layers\n",
    "\n",
    "### The most basic type of neural network layer is a linear or fully connected layer. This is a layer where every input influences every output of the layer to a degree specified by the layer’s weights. If a model has m inputs and n outputs, the weights will be an m x n matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "tensor([[0.9332, 0.9424, 0.9149]])\n",
      "\n",
      "\n",
      "Weight and Bias parameters:\n",
      "Parameter containing:\n",
      "tensor([[ 0.1983, -0.3024,  0.5127],\n",
      "        [-0.0189,  0.4520,  0.3182]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.5734, 0.4034], requires_grad=True)\n",
      "\n",
      "\n",
      "Output:\n",
      "tensor([[0.9425, 1.1028]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lin = torch.nn.Linear(3, 2)\n",
    "x = torch.rand(1, 3)\n",
    "print('Input:')\n",
    "print(x)\n",
    "\n",
    "# The weights and biases of the linear layer are initialized randomly\n",
    "print('\\n\\nWeight and Bias parameters:')\n",
    "for param in lin.parameters():\n",
    "    print(param)\n",
    "\n",
    "y = lin(x)\n",
    "print('\\n\\nOutput:')\n",
    "print(y)\n",
    "\n",
    "# If you do the matrix multiplication of x by the linear layer’s weights, \n",
    "# and add the biases, you’ll find that you get the output vector y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional layers are built to handle data with a high degree of spatial correlation. They are very commonly used in computer vision, where they detect close groupings of features which the compose into higher-level features. They pop up in other contexts too - for example, in NLP applications, where a word’s immediate context (that is, the other words nearby in the sequence) can affect the meaning of a sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel (black & white), 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        # The max pooling layer takes features near each other in the activation map and groups them together.\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Image batch shape:\n",
      "torch.Size([1, 1, 32, 32])\n",
      "\n",
      "Raw output:\n",
      "tensor([[ 0.0284, -0.0938, -0.1077, -0.0768,  0.0210, -0.0295,  0.0396, -0.0268,\n",
      "         -0.0914,  0.1199]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "net = LeNet()\n",
    "print(net)                         # what does the object tell us about itself?\n",
    "\n",
    "input = torch.rand(1, 1, 32, 32)   # stand-in for a 32x32 black & white image\n",
    "print('\\nImage batch shape:')\n",
    "print(input.shape)\n",
    "\n",
    "output = net(input)                # we don't call forward() directly\n",
    "print('\\nRaw output:')\n",
    "print(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Layers\n",
    "\n",
    "### Recurrent neural networks (or RNNs) are used for sequential data - anything from time-series measurements from a scientific instrument to natural language sentences to DNA nucleotides. An RNN does this by maintaining a hidden state that acts as a sort of memory for what it has seen in the sequence so far.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Embeddings are numerical representations of real-world objects like images, videos or words.\n",
    "        # e.g words with similar meanings are close together in the space.\n",
    "        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence) # Converts the input word indices into word embeddings.\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1) # Applies the log-softmax function to produce log-probabilities for each tag.\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers\n",
    "\n",
    "### Allows you to define the overall parameters of a transformer model - the number of attention heads, the number of encoder & decoder layers, dropout and activation functions, etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other layers\n",
    "\n",
    "### Data Manipulation Layers\n",
    "\n",
    "#### Max pooling (and its twin, min pooling) reduce a tensor by combining cells, and assigning the maximum value of the input cells to the output cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.8401, 0.6217, 0.3480, 0.3335, 0.1779, 0.5798],\n",
      "         [0.5546, 0.5826, 0.5134, 0.3894, 0.1720, 0.8062],\n",
      "         [0.5262, 0.5287, 0.7235, 0.1462, 0.0269, 0.5949],\n",
      "         [0.4697, 0.5153, 0.3973, 0.7915, 0.5233, 0.7882],\n",
      "         [0.0255, 0.6345, 0.3991, 0.1427, 0.9327, 0.3483],\n",
      "         [0.6112, 0.4589, 0.5478, 0.2161, 0.3562, 0.0699]]])\n",
      "tensor([[[0.8401, 0.8062],\n",
      "         [0.6345, 0.9327]]])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 6, 6)\n",
    "print(my_tensor)\n",
    "\n",
    "maxpool_layer = torch.nn.MaxPool2d(3)\n",
    "print(maxpool_layer(my_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization layers re-center and normalize the output of one layer before feeding it to another. Centering and scaling the intermediate tensors has a number of beneficial effects, such as letting you use higher learning rates without exploding/vanishing gradients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[19.4567, 14.6704, 19.9919, 13.8026],\n",
      "         [18.2412, 11.4850, 16.4616,  7.6896],\n",
      "         [ 9.0689, 12.4020, 22.6494, 24.1114],\n",
      "         [17.0753,  8.1510,  8.0968, 11.2819]]])\n",
      "tensor(14.6647)\n",
      "tensor([[[ 0.8948, -0.8347,  1.0882, -1.1483],\n",
      "         [ 1.1484, -0.4775,  0.7201, -1.3909],\n",
      "         [-1.2382, -0.7216,  0.8666,  1.0932],\n",
      "         [ 1.6207, -0.8208, -0.8356,  0.0357]]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "tensor(1.6391e-07, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 4, 4) * 20 + 5\n",
    "print(my_tensor)\n",
    "\n",
    "print(my_tensor.mean())\n",
    "\n",
    "norm_layer = torch.nn.BatchNorm1d(4)\n",
    "normed_tensor = norm_layer(my_tensor)\n",
    "print(normed_tensor)\n",
    "\n",
    "print(normed_tensor.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
